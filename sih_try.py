# -*- coding: utf-8 -*-
"""SIH TRY

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fftqFfAnBvma5ZFxibz2q4LCejQCl2Tq
"""

!pip install opendatasets --upgrade --quiet
!pip install jovian --upgrade --quiet

import pandas as pd
import os
import jovian
import opendatasets as od
import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from tqdm import tqdm

# For reproducibility
np.random.seed(42)
tf.random.set_seed(42)

# Assign the Kaggle data set URL into variable
dataset = 'https://www.kaggle.com/datasets/winterrain68/celeb-dataset?select=Celeb-DF-v2u'
# Using opendatasets let's download the data sets
od.download(dataset)

import os

# Specify the folder where the dataset is downloaded
dataset_folder = '/content/celeb-dataset'

# List the files in the dataset folder
files = os.listdir(dataset_folder)

# Print the first few files
print(files[:5])

# Now you can load and view the files (e.g., videos, images)

import os

# Path to the main dataset folder
dataset_folder = '/content/celeb-dataset'

# List contents of Celeb-DF and Celeb-DF-v2 subfolders
celeb_df_v1 = os.listdir(os.path.join(dataset_folder, '/content/celeb-dataset/Celeb-DF'))
celeb_df_v2 = os.listdir(os.path.join(dataset_folder, '/content/celeb-dataset/Celeb-DF-v2'))

# Print the first few files in each folder
print("Files in Celeb-DF:")
print(celeb_df_v1[:5])

print("\nFiles in Celeb-DF-v2:")
print(celeb_df_v2[:5])

import cv2
import matplotlib.pyplot as plt

# Function to load a video and extract frames
def load_video(video_path):
    cap = cv2.VideoCapture(video_path)
    frames = []

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        frames.append(frame)

    cap.release()
    return frames

# Display a few frames from a video
def display_video_frames(video_path, num_frames=5):
    frames = load_video(video_path)
    for i in range(min(num_frames, len(frames))):
        plt.imshow(cv2.cvtColor(frames[i], cv2.COLOR_BGR2RGB))
        plt.title(f'Frame {i+1}')
        plt.axis('off')
        plt.show()

# Pick a sample video from the Celeb-DF-v2 folder
sample_video_path = os.path.join(dataset_folder, '/content/celeb-dataset/Celeb-DF-v2', '/content/celeb-dataset/Celeb-DF-v2/Celeb-synthesis/id0_id16_0002.mp4')
display_video_frames(sample_video_path)

"""Prepare Data for CNN"""

import os
import cv2
import numpy as np
import tensorflow as tf
from keras import backend as K
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from sklearn.model_selection import train_test_split

# Step 1: Clear any previous session
K.clear_session()

# Step 2: Load and preprocess video frames
def load_video(video_path, max_frames=100):
    cap = cv2.VideoCapture(video_path)
    frames = []

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret or len(frames) >= max_frames:
            break
        frame = cv2.resize(frame, (224, 224))  # Resize to match CNN input
        frames.append(frame)

    cap.release()
    return frames

# Step 3: Prepare the dataset
def prepare_data(video_paths, labels, max_frames=100):
    X = []
    y = []

    for video_path, label in zip(video_paths, labels):
        frames = load_video(video_path, max_frames)
        X.extend(frames)
        y.extend([label] * len(frames))

    X = np.array(X).astype('float32') / 255.0  # Normalize
    y = np.array(y)

    return X, y

# Example video paths and labels
# Replace with actual paths to your videos
video_paths = [
    '/content/celeb-dataset/Celeb-DF-v2/Celeb-synthesis/id0_id16_0002.mp4'
]
labels = [0, 0]  # 0 for real, 1 for fake

# Step 4: Prepare the data
X, y = prepare_data(video_paths, labels)

# Step 5: Split the dataset
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 6: Define the CNN model
model = Sequential()

model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Step 7: Train the model
history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=16)

# Step 8: Evaluate the model
loss, accuracy = model.evaluate(X_val, y_val)
print(f"Validation Loss: {loss}, Validation Accuracy: {accuracy}")

"""Step 9: Make Predictions on New Videos"""

# Step 9: Predict Deep Fake
def predict_deepfake(video_path, model):
    frames = load_video(video_path)
    frames = np.array(frames).astype('float32') / 255.0  # Normalize
    predictions = model.predict(frames)

    # Average prediction over all frames
    avg_prediction = np.mean(predictions)

    if avg_prediction > 0.5:
        label = 'Deep Fake'
    else:
        label = 'Real'

    return label, avg_prediction

# Example of prediction on a test video
test_video_path = '/content/celeb-dataset/Celeb-DF-v2/Celeb-synthesis/id0_id16_0002.mp4'
label, confidence = predict_deepfake(test_video_path, model)
print(f"Prediction: {label}, Confidence: {confidence}")

"""step10: Generate a Detailed Report"""

import json

# Step 10: Generate Report
def generate_report(video_path, label, confidence):
    report = {}
    report['Video Path'] = video_path
    report['Prediction'] = label
    # Change confidence from numpy float32 to python float
    report['Confidence'] = float(confidence)

    if label == 'Deep Fake':
        report['Abnormalities'] = 'Detected frame inconsistencies and temporal anomalies.'
        report['Suspected Technique'] = 'Face-swap using GANs'
    else:
        report['Abnormalities'] = 'No significant abnormalities detected.'
        report['Suspected Technique'] = 'N/A'

    return report

# Generate and save report
report = generate_report(test_video_path, label, confidence)
print("Deep Fake Detection Report:")
for key, value in report.items():
    print(f"{key}: {value}")

# Save the report as a JSON file
output_report_path = 'deepfake_report.json'
with open(output_report_path, 'w') as f:
    json.dump(report, f, indent=4)

print(f"Report saved to {output_report_path}")

# Step 11: Save the Trained Model
model.save('deepfake_detection_model.h5')
print("Model saved as deepfake_detection_model.h5")

"""Step 12: Load and Use the Model for Future Predictions"""

# Step 12: Load and Use the Model
from keras.models import load_model

# Load the saved model
loaded_model = load_model('deepfake_detection_model.h5')

# Predict with the loaded model
loaded_label, loaded_confidence = predict_deepfake(test_video_path, loaded_model)
print(f"Loaded Model Prediction: {loaded_label}, Confidence: {loaded_confidence}")